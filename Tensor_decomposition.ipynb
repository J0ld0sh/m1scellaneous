{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjl6x6og3uXH"
   },
   "source": [
    "# HW 1 - Разложение матриц градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sv79QFb_-oNZ"
   },
   "source": [
    "Цель задания: В ходе реализации [разложения Таккера](https://proceedings.neurips.cc/paper/2018/file/45a766fa266ea2ebeb6680fa139d2a3d-Paper.pdf) градиентным методом отработать подходы оптимизации параметров нейросети (в отсутствии готовых решений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HUSrylpBwYn"
   },
   "source": [
    "[Более-менее внятное описание алгоритма канонического разложения](https://www.alexejgossmann.com/tensor_decomposition_tucker/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1PuoBtG7iw7",
    "outputId": "a7eb2592-ac5b-4d16-eb80-a3e7f07bf25b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d79473a230>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import svd, matrix_rank, pinv, inv\n",
    "from scipy.linalg import eigh, eig\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22.3\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print (numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import partial_tucker \n",
    "from tensorly import unfold\n",
    "from tensorly import fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(tensor, mode=0):\n",
    "    \"\"\"Unfolds a tensors following the Kolda and Bader definition\n",
    "\n",
    "        Moves the `mode` axis to the beginning and reshapes in Fortran order\n",
    "    \"\"\"\n",
    "    return torch.reshape(torch.moveaxis(tensor, mode, 0), \n",
    "                      (tensor.shape[mode], -1))\n",
    "def fold(unfolded_tensor, mode, shape):\n",
    "    \"\"\"Refolds the mode-`mode` unfolding into a tensor of shape `shape`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    unfolded_tensor : ndarray\n",
    "        unfolded tensor of shape ``(shape[mode], -1)``\n",
    "    mode : int\n",
    "        the mode of the unfolding\n",
    "    shape : tuple\n",
    "        shape of the original tensor before unfolding\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        folded_tensor of shape `shape`\n",
    "    \"\"\"\n",
    "    full_shape = list(shape)\n",
    "    mode_dim = full_shape.pop(mode)\n",
    "    full_shape.insert(0, mode_dim)\n",
    "    return torch.moveaxis(torch.reshape(unfolded_tensor, full_shape), 0, mode)\n",
    "def mode_dot(tensor, matrix_or_vector, mode):\n",
    "    \"\"\"n-mode product of a tensor by a matrix at the specified mode.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : ndarray\n",
    "        tensor of shape ``(i_1, ..., i_k, ..., i_N)``\n",
    "    matrix_or_vector : ndarray\n",
    "        1D or 2D array of shape ``(J, i_k)`` or ``(i_k, )``\n",
    "        matrix or vectors to which to n-mode multiply the tensor\n",
    "    mode : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        `mode`-mode product of `tensor` by `matrix_or_vector`\n",
    "        * of shape :math:`(i_1, ..., i_{k-1}, J, i_{k+1}, ..., i_N)` if matrix_or_vector is a matrix\n",
    "        * of shape :math:`(i_1, ..., i_{k-1}, i_{k+1}, ..., i_N)` if matrix_or_vector is a vector\n",
    "    \"\"\"\n",
    "    # the mode along which to fold might decrease if we take product with a vector\n",
    "    fold_mode = mode\n",
    "    new_shape = list(tensor.shape)\n",
    "\n",
    "    # tensor times vector case: make sure the sizes are correct \n",
    "    # (we are contracting over one dimension which then disappearas)\n",
    "    if matrix_or_vector.ndim == 1: \n",
    "        if len(new_shape) > 1:\n",
    "            new_shape.pop(mode)\n",
    "            fold_mode -= 1\n",
    "        else:\n",
    "            new_shape = [1]\n",
    "    # This is the actual operation: we use the equivalent formulation of the n-mode-product using the unfolding\n",
    "    res = torch.matmul(matrix_or_vector, unfold(tensor, (mode))) \n",
    "\n",
    "    new_shape[mode] = matrix_or_vector.shape[0]\n",
    "    return fold(res, mode, new_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LfhKpuX7htE"
   },
   "source": [
    "## 1 Создайте 3х мерный тензор\n",
    "Размер тензора не меньше 100 по каждой из размерностей.\n",
    "\n",
    "Заполните случайными целыми числами в диапазоне от 0 до 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap1Ozn7P8-Yj"
   },
   "source": [
    "Примечание: разложение будет корректно работать со случайным тензором, только если изначально создавать случайные ядро и матрицы, а потом по ним формировать тензор. Работайте с типом *torch.Tensor.double*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5SzHzteOROQQ"
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "from numpy.random import randint\n",
    "# Создадим тензор: размер тензора и r задаётся\n",
    "def get_tensor(size=(100,200,150), r=10):\n",
    "  # data - тензор с заданной размерностью\n",
    "  # U - список матриц\n",
    "  # G - ядро разложения\n",
    "    G = torch.tensor(randint(0, 9, r**3).reshape(r,r,r)) \n",
    "    G = G.double()\n",
    "    U = []\n",
    "    data = G.detach().clone()\n",
    "    for i in range(0, 3):\n",
    "        A = torch.tensor(randint(0, 9, r*size[i]).reshape(size[i], r))\n",
    "        A = A.to(dtype=torch.float64)\n",
    "        data = mode_dot(data, A, mode= i)\n",
    "        U.append(A)\n",
    "    data = torch.floor(data*9/(data.max() - data.min()))\n",
    "    data += torch.ones(100, 200, 150)*1e-2\n",
    "    #data = data.to(dtype=torch.float64)\n",
    "    return U, data, G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N70Xy_6u9RFa"
   },
   "outputs": [],
   "source": [
    "U,data,core = get_tensor(size=(400, 500, 500), r = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 500, 500])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp75_Ad29RL5"
   },
   "source": [
    "Вопрос:\n",
    "Почему задание не имеет смысла для полностью случайного тензора и зачем добавлять шум? *не отвечать нельзя*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oo4KhO9Q9YlL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKqzxtaE-F16"
   },
   "source": [
    "## 2 Сделайте разложение библиотечным методом\n",
    "Пакет можете брать любой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGXet3fw9SSh",
    "outputId": "b0cd0ab6-9640-4b9a-e099-e8ea6c8d3d03"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorly\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 500, 500])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Hlp4Jh3--fKh"
   },
   "outputs": [],
   "source": [
    "from tensorly.decomposition import tucker\n",
    "X = tl.tensor(data)\n",
    "core, factors = tucker(X, rank=[20, 20, 20])\n",
    "core_torch = torch.from_numpy(core)\n",
    "factors_torch = []\n",
    "for factor in factors:\n",
    "    factors_torch.append(torch.from_numpy(factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decomposed = core_torch.detach().clone()\n",
    "i = 0\n",
    "for factor in factors_torch:\n",
    "    Decomposed = mode_dot(Decomposed, factor, i)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 500, 500])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decomposed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMw1x8w8-lsh"
   },
   "source": [
    "Не забудьте померить ошибку разложения по метрике MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HWkdb7Ip-mL3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0137, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "loss = torch.norm(Decomposed.data - data.data, 2)/torch.norm(data.data, 2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibOgeEgfD1wm"
   },
   "source": [
    "## 3 Реализуйте разложение градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzninpMYD_hd"
   },
   "source": [
    "### 3.1 Реализуйте метод для восстановления тензора по разложению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YDTx9ZbYD-_S"
   },
   "outputs": [],
   "source": [
    "def repair_tensor(G_, U):\n",
    "  # data - восстановленный тензор из матриц и ядра\n",
    "  # U - список матриц\n",
    "  # G_ - ядро разложения\n",
    "    data = G_.detach().clone()\n",
    "    i = 0\n",
    "    for u in U:\n",
    "        data = mode_dot(data, u, i)\n",
    "        data.retain_grad()\n",
    "        i += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GstBYmiBF7A6"
   },
   "source": [
    "### 3.2 Реализуйте *optimizer*\n",
    "Можно взять из исходников *PyTorch* и отнаследоваться от *torch.optim.optimizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Mxrtt60hF6xb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch import autograd\n",
    "\n",
    "\n",
    "class Opt(Optimizer):\n",
    "    def __init__(self, params, # params: model.parameters()\n",
    "                       lr: float = 1e-3, # input: type = value\n",
    "                 weight_decay=0.\n",
    "                 ): \n",
    "        # constructor\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay) \n",
    "        # add a default attribute that can be accessed\n",
    "        super(Opt, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None): \n",
    "        loss= None\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "                grad_param = param.grad.data\n",
    "                \n",
    "                if weight_decay != 0:\n",
    "                    grad_param += weight_decay*param.data\n",
    "\n",
    "                param.data -= group['lr']*grad_paramcx \n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly import backend as T\n",
    "from torch import nn\n",
    "from mxnet import nd, autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GSolH5dEJba"
   },
   "source": [
    "### 3.3 Реализуйте цикл оптимизации параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6UWpuERFTn8"
   },
   "source": [
    "Стоит параметры оптимизировать сразу на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "CgPaeQ7XEJnD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def Decomp(r, X):\n",
    "    \n",
    "    torch.manual_seed(42)\n",
    "    core = torch.randn(r,r,r, requires_grad=True, dtype=torch.float64)\n",
    "    factors = [torch.rand(X.shape[i], r, requires_grad=True, dtype=torch.float64) for i in range(3)] \n",
    "    core.cuda()\n",
    "    for i in factors:\n",
    "        i.cuda()\n",
    "\n",
    "    n_iter = 1201\n",
    "    lr = 1e-4\n",
    "    penalty = 0.6\n",
    "    X.cuda()\n",
    "\n",
    "    optimizer = Opt([core]+factors, lr)\n",
    "\n",
    "    for i in range(1, n_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    # Reconstruct the tensor from the decomposed form\n",
    "        rec = repair_tensor(core, factors)\n",
    "\n",
    "    # squared l2 loss\n",
    "        loss = torch.norm(rec - X, 2)\n",
    "\n",
    "    # squared l2 penalty on the factors of the decomposition\n",
    "        for f in factors:\n",
    "            loss = loss + penalty * f.pow(2).sum()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        rec_error = 0\n",
    "        if i % 100 == 0:\n",
    "            rec_error = torch.norm(rec.data - X.data, 2)/torch.norm(X.data, 2)\n",
    "            print(\"Epoch {},. Rec. error: {}\".format(i, rec_error))\n",
    "    return rec_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za8JKgR-Falk"
   },
   "source": [
    "## 4 Приведите сравнение скорости работы и ошибки восстановления методом из пакета и реализованного градиентного\n",
    "Сравнение может считаться ± объективным с размером выборки от 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "mOGKW9RHFa5D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-tensor\n",
      "torch.Size([190, 297, 145])\n",
      "Epoch 100,. Rec. error: 0.5062390727699241\n",
      "Epoch 200,. Rec. error: 0.30320337524080654\n",
      "Epoch 300,. Rec. error: 0.22178615699745957\n",
      "Epoch 400,. Rec. error: 0.1837834499285692\n",
      "Epoch 500,. Rec. error: 0.1643184007553727\n",
      "Epoch 600,. Rec. error: 0.15364186585230777\n",
      "Epoch 700,. Rec. error: 0.14740561679374586\n",
      "Epoch 800,. Rec. error: 0.14353424287483538\n",
      "Epoch 900,. Rec. error: 0.14099326417843364\n",
      "Epoch 1000,. Rec. error: 0.13924348516974147\n",
      "Epoch 1100,. Rec. error: 0.1379894952938641\n",
      "Epoch 1200,. Rec. error: 0.13706093934797892\n",
      "1-tensor\n",
      "torch.Size([248, 234, 217])\n",
      "Epoch 100,. Rec. error: 0.4358419991908741\n",
      "Epoch 200,. Rec. error: 0.2664039233100596\n",
      "Epoch 300,. Rec. error: 0.19572607429741753\n",
      "Epoch 400,. Rec. error: 0.16166162278546686\n",
      "Epoch 500,. Rec. error: 0.14410567420491374\n",
      "Epoch 600,. Rec. error: 0.13462554287001305\n",
      "Epoch 700,. Rec. error: 0.12921075919910358\n",
      "Epoch 800,. Rec. error: 0.12592084869182749\n",
      "Epoch 900,. Rec. error: 0.12380414161296888\n",
      "Epoch 1000,. Rec. error: 0.12237458300388093\n",
      "Epoch 1100,. Rec. error: 0.1213698188490906\n",
      "Epoch 1200,. Rec. error: 0.12064007090614569\n",
      "2-tensor\n",
      "torch.Size([258, 294, 266])\n",
      "Epoch 100,. Rec. error: 0.591261473707568\n",
      "Epoch 200,. Rec. error: 0.353706466682813\n",
      "Epoch 300,. Rec. error: 0.2641273389291054\n",
      "Epoch 400,. Rec. error: 0.22448713876414034\n",
      "Epoch 500,. Rec. error: 0.20430067321627268\n",
      "Epoch 600,. Rec. error: 0.19293252612186812\n",
      "Epoch 700,. Rec. error: 0.18607757103012948\n",
      "Epoch 800,. Rec. error: 0.18171930433639952\n",
      "Epoch 900,. Rec. error: 0.1788178436919228\n",
      "Epoch 1000,. Rec. error: 0.1768055059061143\n",
      "Epoch 1100,. Rec. error: 0.17535906618946787\n",
      "Epoch 1200,. Rec. error: 0.17428711997054636\n",
      "3-tensor\n",
      "torch.Size([299, 272, 192])\n",
      "Epoch 100,. Rec. error: 0.5185669833565559\n",
      "Epoch 200,. Rec. error: 0.30959781935540015\n",
      "Epoch 300,. Rec. error: 0.22867373892382759\n",
      "Epoch 400,. Rec. error: 0.19232075107328572\n",
      "Epoch 500,. Rec. error: 0.174175465805584\n",
      "Epoch 600,. Rec. error: 0.1643755723477305\n",
      "Epoch 700,. Rec. error: 0.15867924826828345\n",
      "Epoch 800,. Rec. error: 0.15512626991320994\n",
      "Epoch 900,. Rec. error: 0.15276848582473748\n",
      "Epoch 1000,. Rec. error: 0.15112226982988736\n",
      "Epoch 1100,. Rec. error: 0.1499254888888923\n",
      "Epoch 1200,. Rec. error: 0.14902721852249423\n",
      "4-tensor\n",
      "torch.Size([282, 143, 248])\n",
      "Epoch 100,. Rec. error: 0.5406655035537634\n",
      "Epoch 200,. Rec. error: 0.32798896548682854\n",
      "Epoch 300,. Rec. error: 0.24523657374239202\n",
      "Epoch 400,. Rec. error: 0.20641865647112895\n",
      "Epoch 500,. Rec. error: 0.18613006230551316\n",
      "Epoch 600,. Rec. error: 0.1746769620810812\n",
      "Epoch 700,. Rec. error: 0.16774460112857031\n",
      "Epoch 800,. Rec. error: 0.16326751122926056\n",
      "Epoch 900,. Rec. error: 0.1602106161907043\n",
      "Epoch 1000,. Rec. error: 0.15802779145923124\n",
      "Epoch 1100,. Rec. error: 0.15641366310331292\n",
      "Epoch 1200,. Rec. error: 0.15518729077177593\n",
      "5-tensor\n",
      "torch.Size([275, 164, 239])\n",
      "Epoch 100,. Rec. error: 0.4836280720583584\n",
      "Epoch 200,. Rec. error: 0.29494040218852063\n",
      "Epoch 300,. Rec. error: 0.2186401034475845\n",
      "Epoch 400,. Rec. error: 0.1820558088095503\n",
      "Epoch 500,. Rec. error: 0.16306168739765722\n",
      "Epoch 600,. Rec. error: 0.15263061327949767\n",
      "Epoch 700,. Rec. error: 0.14651604835130008\n",
      "Epoch 800,. Rec. error: 0.14267452822958746\n",
      "Epoch 900,. Rec. error: 0.14010863570243864\n",
      "Epoch 1000,. Rec. error: 0.13830927399926535\n",
      "Epoch 1100,. Rec. error: 0.13699951357606116\n",
      "Epoch 1200,. Rec. error: 0.13601847231869477\n",
      "6-tensor\n",
      "torch.Size([214, 158, 197])\n",
      "Epoch 100,. Rec. error: 0.5408631603870663\n",
      "Epoch 200,. Rec. error: 0.3323264434826202\n",
      "Epoch 300,. Rec. error: 0.24422389799723102\n",
      "Epoch 400,. Rec. error: 0.20078811581159067\n",
      "Epoch 500,. Rec. error: 0.1772682280922553\n",
      "Epoch 600,. Rec. error: 0.16376207676462437\n",
      "Epoch 700,. Rec. error: 0.15564598583489853\n",
      "Epoch 800,. Rec. error: 0.1505436255223951\n",
      "Epoch 900,. Rec. error: 0.14718629490033458\n",
      "Epoch 1000,. Rec. error: 0.14488138412026647\n",
      "Epoch 1100,. Rec. error: 0.14323965181385231\n",
      "Epoch 1200,. Rec. error: 0.14203389096830762\n"
     ]
    }
   ],
   "source": [
    "tensors = []\n",
    "loss_paket = []\n",
    "loss_my = []\n",
    "\n",
    "time_exec_my = []\n",
    "time_exec_pocket = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(7):\n",
    "    print('{}-tensor'.format(i))\n",
    "    size = (randint(100, 300),randint(100, 300),randint(100, 300))\n",
    "    t2nsor = get_tensor(size, r=10)[1]\n",
    "    tensors.append(t2nsor)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(t2nsor.shape)\n",
    "    The_loss = Decomp(10, t2nsor)\n",
    "    time_exec_my.append(start_time - time.time())\n",
    "    loss_my.append(The_loss)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    X = tl.tensor(t2nsor)\n",
    "    core, factors = tucker(X, rank=[20, 20, 20])    \n",
    "    \n",
    "    core_torch = torch.from_numpy(core)\n",
    "    factors_torch = []\n",
    "    for factor in factors:\n",
    "        factors_torch.append(torch.from_numpy(factor.copy()))\n",
    "    \n",
    "    Decomposed = core_torch.detach().clone()\n",
    "    i = 0\n",
    "    for factor in factors_torch:\n",
    "        Decomposed = mode_dot(Decomposed, factor, i)\n",
    "        i += 1\n",
    "    loss_paket.append(torch.norm(Decomposed.data - t2nsor.data, 2)/torch.norm(t2nsor.data, 2))\n",
    "    time_exec_pocket.append(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1371, dtype=torch.float64) tensor(0.0676, dtype=torch.float64)\n",
      "tensor(0.1206, dtype=torch.float64) tensor(0.0613, dtype=torch.float64)\n",
      "tensor(0.1743, dtype=torch.float64) tensor(0.0757, dtype=torch.float64)\n",
      "tensor(0.1490, dtype=torch.float64) tensor(0.0686, dtype=torch.float64)\n",
      "tensor(0.1552, dtype=torch.float64) tensor(0.0718, dtype=torch.float64)\n",
      "tensor(0.1360, dtype=torch.float64) tensor(0.0672, dtype=torch.float64)\n",
      "tensor(0.1420, dtype=torch.float64) tensor(0.0662, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(loss_my)):\n",
    "    print(loss_my[i], loss_paket[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean error of my decomposition =  0.1448935718294205\n",
      "mean error of module decomposition =  0.06834384146763782\n"
     ]
    }
   ],
   "source": [
    "print(\"mean error of my decomposition = \",np.array(loss_my).mean())\n",
    "print(\"mean error of module decomposition = \",np.array(loss_paket).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\4227~1\\AppData\\Local\\Temp/ipykernel_20216/3412263049.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mranks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfactors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rng' is not defined"
     ]
    }
   ],
   "source": [
    "ranks = [5, 5, 5]\n",
    "\n",
    "core = T.tensor(rng.random_sample(ranks))\n",
    "factors = [T.tensor(rng.random_sample((tensor.shape[i], ranks[i]))) for i in range(tensor.ndim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "core = torch.randn(r, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(core.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9806, -0.2274, -0.3693, -1.0661, -1.1803, -1.1742, -0.0673, -0.3317,\n",
       "         3.0527, -0.7597, -0.8742, -1.5350,  0.6282, -0.5962,  0.4910, -0.0620,\n",
       "         0.7298, -1.1375,  0.4975, -1.6329], requires_grad=True)"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         ...,\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],\n",
       "\n",
       "        [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         ...,\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],\n",
       "\n",
       "        [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         ...,\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         ...,\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],\n",
       "\n",
       "        [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         ...,\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]],\n",
       "\n",
       "        [[0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         ...,\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100],\n",
       "         [0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100]]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
